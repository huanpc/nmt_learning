{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F33sncleXVX6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Download Data"
      ]
    },
    {
      "metadata": {
        "id": "qx_-7-TJPINZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "9584cdd5-9da0-4845-997d-252dc8b0aa6a"
      },
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jan  8 17:15 sample_data\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GhN2dyx39zlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "24e46a3d-fc1c-4101-bcda-8071cc9cef19"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwx------ 3 root root 4096 Jan 21 15:07 gdrive\n",
            "drwxr-xr-x 1 root root 4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNt9jBO7XU35",
        "colab_type": "code",
        "outputId": "c7f8919d-8e14-4ab6-c187-9bc2ceffe2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir gdrive/My\\ Drive/nmt\n",
        "!curl -X GET https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/scripts/download_iwslt15.sh -o gdrive/My\\ Drive/nmt/download_iwslt15.sh\n",
        "!mkdir gdrive/My\\ Drive/nmt/nmt_data\n",
        "!chmod +x gdrive/My\\ Drive/nmt/download_iwslt15.sh && ./gdrive/My\\ Drive/nmt/download_iwslt15.sh gdrive/My\\ Drive/nmt/nmt_data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘gdrive/My Drive/nmt’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1188  100  1188    0     0  28975      0 --:--:-- --:--:-- --:--:-- 28975\n",
            "mkdir: cannot create directory ‘gdrive/My’: Operation not supported\n",
            "Download training dataset train.en and train.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.9M  100 12.9M    0     0  2376k      0  0:00:05  0:00:05 --:--:-- 2965k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17.2M  100 17.2M    0     0  2386k      0  0:00:07  0:00:07 --:--:-- 3453k\n",
            "Download dev dataset tst2012.en and tst2012.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0   106k      0  0:00:01  0:00:01 --:--:--  106k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  183k  100  183k    0     0   130k      0  0:00:01  0:00:01 --:--:--  130k\n",
            "Download test dataset tst2013.en and tst2013.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  129k  100  129k    0     0   101k      0  0:00:01  0:00:01 --:--:--  101k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  179k  100  179k    0     0   127k      0  0:00:01  0:00:01 --:--:--  127k\n",
            "Download vocab file vocab.en and vocab.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0   106k      0  0:00:01  0:00:01 --:--:--  106k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 46767  100 46767    0     0  54762      0 --:--:-- --:--:-- --:--:-- 54698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x0xVEaun4huM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/My\\ Drive/nmt/nmt_data nmt_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Op9VHiq6Emq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "20eeb4c7-c7f5-4835-88a8-1ed90f751a08"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 3 root root 4096 Jan 21 15:11 Drive\n",
            "drwx------ 3 root root 4096 Jan 21 15:07 gdrive\n",
            "drwx------ 8 root root 4096 Jan 21 15:34 nmt\n",
            "drwx------ 2 root root 4096 Jan 21 15:40 nmt_data\n",
            "drwxr-xr-x 1 root root 4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p7-VUfjd4mkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Clone code"
      ]
    },
    {
      "metadata": {
        "id": "ElTCEn4w4oMh",
        "colab_type": "code",
        "outputId": "8a8e7b11-4211-414f-ff01-d33add6406f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!cd gdrive/My\\ Drive/nmt && git clone https://github.com/tensorflow/nmt.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nmt'...\n",
            "remote: Enumerating objects: 1247, done.\u001b[K\n",
            "remote: Total 1247 (delta 0), reused 0 (delta 0), pack-reused 1247\u001b[K\n",
            "Receiving objects: 100% (1247/1247), 1.22 MiB | 2.35 MiB/s, done.\n",
            "Resolving deltas: 100% (892/892), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rn9r90w-tAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!CODE_DIR=\"gdrive/My\\ Drive/nmt\"\n",
        "!DATA_DIR=\"gdrive/My\\ Drive/nmt/nmt_data\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wx91RpEL5jeX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Tensor Board"
      ]
    },
    {
      "metadata": {
        "id": "G3j6Shf45wF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download"
      ]
    },
    {
      "metadata": {
        "id": "9DopEXs_5mCf",
        "colab_type": "code",
        "outputId": "9429caf1-d7d0-40c1-9caf-ac1fc1451f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!rm -rf ngrok\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-21 02:37:28--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.204.22.7, 34.206.9.96, 34.206.253.53, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.204.22.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  33%[=====>              ]   1.70M  7.88MB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  20.3MB/s    in 0.3s    \n",
            "\n",
            "2019-01-21 02:37:29 (20.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wK5U-QjPYbP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ]
    },
    {
      "metadata": {
        "id": "FA7zXiac5Fwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1 Basic"
      ]
    },
    {
      "metadata": {
        "id": "HKAdyn_x5tDk",
        "colab_type": "code",
        "outputId": "5030afd4-41c8-4443-b5a8-ca5105ff314b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1425
        }
      },
      "cell_type": "code",
      "source": [
        "tsboard_cmd = 'tensorboard --logdir nmt_model --host 0.0.0.0 --port 6006 &'\n",
        "print(\"Log dir\", tsboard_cmd)\n",
        "get_ipython().system_raw(tsboard_cmd)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log dir tensorboard --logdir nmt_model --host 0.0.0.0 --port 6006 &\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 106, in <module>\n",
            "    from .decoder import JSONDecoder, JSONDecodeError\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 53, in <module>\n",
            "    STRINGCHUNK = re.compile(r'(.*?)([\"\\\\\\x00-\\x1f])', FLAGS)\n",
            "  File \"/usr/lib/python3.6/re.py\", line 233, in compile\n",
            "    return _compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.6/re.py\", line 301, in _compile\n",
            "    p = sre_compile.compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 566, in compile\n",
            "    code = _code(p, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 551, in _code\n",
            "    _compile(code, p.data, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
            "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 72, in _compile\n",
            "    if (flags & SRE_FLAG_IGNORECASE and\n",
            "  File \"/usr/lib/python3.6/enum.py\", line 806, in __and__\n",
            "    return self.__class__(self._value_ & self.__class__(other)._value_)\n",
            "  File \"/usr/lib/python3.6/enum.py\", line 293, in __call__\n",
            "    return cls.__new__(cls, value)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-22e8f0c3fdd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsboard_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ngrok http 6006 &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)[\\'tunnels\\'][0][\\'public_url\\'])\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5ZuBbk8oXws4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf nmt_model \n",
        "!mkdir nmt_model\n",
        "!python -m nmt.nmt.nmt \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=nmt_data/vocab  \\\n",
        "    --train_prefix=nmt_data/train \\\n",
        "    --dev_prefix=nmt_data/tst2012  \\\n",
        "    --test_prefix=nmt_data/tst2013 \\\n",
        "    --out_dir=nmt_model \\\n",
        "    --num_train_steps=12000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --num_layers=4 \\\n",
        "    --num_units=128 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpK4sCR94Vxs",
        "colab_type": "code",
        "outputId": "e9208cb7-bc9f-493a-fe53-65ab9ef3580d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 21016\n",
            "-rw-r--r-- 1 root root     2559 Jan 21 02:34 adc.json\n",
            "-rwxr-xr-x 1 root root     1188 Jan 21 02:29 download_iwslt15.sh\n",
            "drwx------ 3 root root     4096 Jan 21 02:28 gdrive\n",
            "-rw-r--r-- 1 root root      198 Jan 21 05:25 infer.vi\n",
            "-rwxr-xr-x 1 root root 16117632 Jul 15  2017 ngrok\n",
            "-rw-r--r-- 1 root root  5363700 Jan 21 02:37 ngrok-stable-linux-amd64.zip\n",
            "drwxr-xr-x 4 root root     4096 Jan 21 02:37 nmt\n",
            "drwxr-xr-x 2 root root     4096 Jan 21 05:25 nmt_attention_model\n",
            "drwxr-xr-x 2 root root     4096 Jan 21 02:30 nmt_data\n",
            "drwxr-xr-x 1 root root     4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7RJzHsKS8f1t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Attention"
      ]
    },
    {
      "metadata": {
        "id": "BuHpV_t-Xcg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3525eeac-5306-49a5-f190-a2751780dba3"
      },
      "cell_type": "code",
      "source": [
        "# Clean old model\n",
        "# !rm -rf gdrive/nmt_attention_model\n",
        "# !mkdir gdrive/nmt_attention_model\n",
        "!MODEL_DIR=\"gdrive/My\\ Drive/nmt/nmt_data\"\n",
        "!echo ${MODEL_DIR}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3eF1GR4z8h0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88a7f07b-5e36-4fee-9e28-98b32555aea9"
      },
      "cell_type": "code",
      "source": [
        "tsboard_cmd = 'tensorboard --logdir nmt_attention_model --host 0.0.0.0 --port 6006 &'\n",
        "print(\"Log dir\", tsboard_cmd)\n",
        "get_ipython().system_raw(tsboard_cmd)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log dir tensorboard --logdir nmt_attention_model --host 0.0.0.0 --port 6006 &\n",
            "http://0c7abc4e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kLkoA0vqjP-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4d88f560-4d4a-4d29-c5c8-2e6e59381a70"
      },
      "cell_type": "code",
      "source": [
        "!curl -X GET https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/standard_hparams/iwslt15.json -o params.json"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   823  100   823    0     0   7620      0 --:--:-- --:--:-- --:--:--  7550\r100   823  100   823    0     0   7550      0 --:--:-- --:--:-- --:--:--  7550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xShDIW2iAfGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d9f67c8f-893e-4104-ab42-2ee7123b4961"
      },
      "cell_type": "code",
      "source": [
        "!ls -l gdrive/My\\ Drive/nmt/nmt/nmt"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 220\n",
            "-rw------- 1 root root  7387 Jan 21 15:14 attention_model.py\n",
            "drwx------ 3 root root  4096 Jan 21 15:14 g3doc\n",
            "-rw------- 1 root root 12252 Jan 21 15:14 gnmt_model.py\n",
            "-rw------- 1 root root  8895 Jan 21 15:14 inference.py\n",
            "-rw------- 1 root root  6490 Jan 21 15:14 inference_test.py\n",
            "-rw------- 1 root root     0 Jan 21 15:14 __init__.py\n",
            "-rw------- 1 root root 24395 Jan 21 15:14 model_helper.py\n",
            "-rw------- 1 root root 33588 Jan 21 15:14 model.py\n",
            "-rw------- 1 root root 48465 Jan 21 15:14 model_test.py\n",
            "-rw------- 1 root root 29123 Jan 21 15:14 nmt.py\n",
            "-rw------- 1 root root  3404 Jan 21 15:14 nmt_test.py\n",
            "drwx------ 2 root root  4096 Jan 21 15:14 scripts\n",
            "drwx------ 2 root root  4096 Jan 21 15:14 standard_hparams\n",
            "drwx------ 2 root root  4096 Jan 21 15:14 testdata\n",
            "-rw------- 1 root root 28948 Jan 21 15:14 train.py\n",
            "drwx------ 2 root root  4096 Jan 21 15:14 utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Th2bEXxb8dMQ",
        "colab_type": "code",
        "outputId": "ec30f9ee-48cc-4ff7-f06f-a522be11faee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5154
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m nmt.nmt \\\n",
        "    --attention=scaled_luong \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=nmt_data/vocab  \\\n",
        "    --train_prefix=nmt_data/train \\\n",
        "    --dev_prefix=nmt_data/tst2012  \\\n",
        "    --test_prefix=nmt_data/tst2013 \\\n",
        "    --out_dir=gdrive/My\\ Drive/nmt_attention_model_2 \\\n",
        "    --num_train_steps=24000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --infer_mode=beam_search\\\n",
        "    --beam_width=10\\\n",
        "    --num_layers=2 \\\n",
        "    --num_units=1024 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu \\\n",
        "    --encoder_type=bi\\\n",
        "    --decay_scheme=luong234\n",
        "    "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Job id 0\n",
            "2019-01-21 15:42:03.172654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-21 15:42:03.173096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-21 15:42:03.173137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 15:42:03.537543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 15:42:03.537609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 15:42:03.537628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 15:42:03.537950: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-21 15:42:03.538057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 17638237294807695963), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6036036529112999179), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 17089580647630454146), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11281553818, 8830476587556170822)]\n",
            "# Loading hparams from gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# Vocab file nmt_data/vocab.vi exists\n",
            "# Vocab file nmt_data/vocab.en exists\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/best_bleu/hparams\n",
            "  attention=scaled_luong\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=10\n",
            "  best_bleu=20.318737759181925\n",
            "  best_bleu_dir=gdrive/My Drive/nmt_attention_model_2/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  decay_scheme=luong234\n",
            "  dev_prefix=nmt_data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=bi\n",
            "  eos=</s>\n",
            "  epoch_step=0\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=beam_search\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=1.0\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=24000\n",
            "  num_translations_per_input=1\n",
            "  num_units=1024\n",
            "  optimizer=sgd\n",
            "  out_dir=gdrive/My Drive/nmt_attention_model_2\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=nmt_data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=nmt_data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=nmt_data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=nmt_data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=nmt_data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "WARNING:tensorflow:From /content/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "# Creating train graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  learning_rate=1, warmup_steps=0, warmup_scheme=t2t\n",
            "  decay_scheme=luong234, start_decay_step=16000, decay_steps 2000, decay_factor 0.5\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 1024), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 1024), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (2048, 1024), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (3072, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (3072, 1024), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (1024, 17191), /device:GPU:0\n",
            "# Creating eval graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 1024), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 1024), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (2048, 1024), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (3072, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (3072, 1024), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (1024, 17191), /device:GPU:0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=beam_searchbeam_width=10, length_penalty=0.000000\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 1024), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 1024), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (2048, 1024), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (3072, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (2048, 4096), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (4096,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (3072, 1024), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (1024, 17191), \n",
            "# log_file=gdrive/My Drive/nmt_attention_model_2/log_1548085330\n",
            "2019-01-21 15:42:10.873381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 15:42:10.873473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 15:42:10.873501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 15:42:10.873521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 15:42:10.873824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-01-21 15:42:10.874296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 15:42:10.874348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 15:42:10.874409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 15:42:10.874423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 15:42:10.874728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-01-21 15:42:10.875251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 15:42:10.875295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 15:42:10.875338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 15:42:10.875356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 15:42:10.875602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "  loaded train model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-23000, time 5.86s\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-23000, time 0.62s\n",
            "  # 632\n",
            "    src: Động cơ , sang số- Có 4 lựa chọn\n",
            "    ref: Engines , gearshift -- four choices .\n",
            "    nmt: The engine , to <unk> , has four options .\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-23000, time 0.61s\n",
            "  eval dev: perplexity 19.94, time 5s, Mon Jan 21 15:42:26 2019.\n",
            "  eval test: perplexity 15.95, time 4s, Mon Jan 21 15:42:31 2019.\n",
            "2019-01-21 15:42:32.252610: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 15:42:32.252779: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 15:42:32.252890: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-23000, time 0.56s\n",
            "# External evaluation, global step 23000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model_2/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 66s, Mon Jan 21 15:43:38 2019.\n",
            "  bleu dev: 19.7\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# External evaluation, global step 23000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model_2/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 63s, Mon Jan 21 15:44:43 2019.\n",
            "  bleu test: 22.3\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# Start step 23000, lr 0.125, Mon Jan 21 15:44:43 2019\n",
            "# Init train iterator, skipping 0 elements\n",
            "2019-01-21 15:44:56.824743: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 78934 of 128000\n",
            "2019-01-21 15:45:02.882089: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.\n",
            "  step 23100 lr 0.125 step-time 1.26s wps 4.39K ppl 1.92 gN 7.55 bleu 20.32, Mon Jan 21 15:46:49 2019\n",
            "  step 23200 lr 0.125 step-time 1.06s wps 5.28K ppl 1.97 gN 7.82 bleu 20.32, Mon Jan 21 15:48:35 2019\n",
            "  step 23300 lr 0.125 step-time 1.07s wps 5.29K ppl 1.98 gN 7.93 bleu 20.32, Mon Jan 21 15:50:23 2019\n",
            "  step 23400 lr 0.125 step-time 1.06s wps 5.31K ppl 1.98 gN 7.86 bleu 20.32, Mon Jan 21 15:52:09 2019\n",
            "  step 23500 lr 0.125 step-time 1.05s wps 5.29K ppl 1.94 gN 7.78 bleu 20.32, Mon Jan 21 15:53:54 2019\n",
            "  step 23600 lr 0.125 step-time 1.06s wps 5.30K ppl 1.99 gN 7.79 bleu 20.32, Mon Jan 21 15:55:39 2019\n",
            "  step 23700 lr 0.125 step-time 1.08s wps 5.32K ppl 2.00 gN 8.04 bleu 20.32, Mon Jan 21 15:57:27 2019\n",
            "  step 23800 lr 0.125 step-time 1.06s wps 5.30K ppl 2.01 gN 7.91 bleu 20.32, Mon Jan 21 15:59:13 2019\n",
            "  step 23900 lr 0.125 step-time 1.06s wps 5.31K ppl 2.02 gN 8.02 bleu 20.32, Mon Jan 21 16:00:59 2019\n",
            "  step 24000 lr 0.125 step-time 1.05s wps 5.29K ppl 1.97 gN 7.88 bleu 20.32, Mon Jan 21 16:02:44 2019\n",
            "# Save eval, global step 24000\n",
            "2019-01-21 16:02:47.111707: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:02:47.111722: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:02:47.111943: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-24000, time 0.59s\n",
            "  # 1482\n",
            "    src: Nếu chính quyền phát hiện ra những tài liệu mang những tư tưởng không đúng đắn họ có thể truy ra ai là chủ nhân của những &quot; tư tưởng lệch lạc &quot; này .\n",
            "    ref: If they found a paper which had the wrong kind of thought , they could track down who created that thought .\n",
            "    nmt: If the government comes to document documents that &apos;s not true , they can help who are these <unk> ideas .\n",
            "2019-01-21 16:02:47.941765: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:02:47.941957: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:02:47.942102: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-24000, time 0.58s\n",
            "  eval dev: perplexity 20.47, time 5s, Mon Jan 21 16:02:53 2019.\n",
            "  eval test: perplexity 16.26, time 5s, Mon Jan 21 16:02:58 2019.\n",
            "2019-01-21 16:03:02.057745: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:03:02.057914: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:03:02.058185: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-24000, time 0.63s\n",
            "  # 1411\n",
            "    src: Và có được ý tưởng này trong suốt mùa đông , tôi biết mình phải mất vài tháng để chuẩn bị , để tìm các địa điểm khác nhau cho các phần của bức ảnh .\n",
            "    ref: And getting this idea during winter , I knew that I had several months to plan it , to find the different locations for the pieces of the puzzle basically .\n",
            "    nmt: And this idea in the winter , I knew that I had to take months to prepare , to find different locations for the scenes .\n",
            "2019-01-21 16:03:02.969156: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:03:02.969365: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:03:02.969475: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-24000, time 0.60s\n",
            "  eval dev: perplexity 20.47, time 5s, Mon Jan 21 16:03:08 2019.\n",
            "  eval test: perplexity 16.26, time 5s, Mon Jan 21 16:03:13 2019.\n",
            "2019-01-21 16:03:14.165078: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:03:14.165095: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:03:14.165284: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/translate.ckpt-24000, time 0.67s\n",
            "# External evaluation, global step 24000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model_2/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 65s, Mon Jan 21 16:04:19 2019.\n",
            "  bleu dev: 19.6\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# External evaluation, global step 24000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model_2/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 62s, Mon Jan 21 16:05:22 2019.\n",
            "  bleu test: 22.5\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# Final, step 24000 lr 0.125 step-time 1.05s wps 5.29K ppl 1.97 gN 7.88 dev ppl 20.47, dev bleu 19.6, test ppl 16.26, test bleu 22.5, Mon Jan 21 16:05:22 2019\n",
            "# Done training!, time 1238s, Mon Jan 21 16:05:22 2019.\n",
            "# Start evaluating saved best models.\n",
            "2019-01-21 16:05:28.142958: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:05:28.142994: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:05:28.143156: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/best_bleu/translate.ckpt-13000, time 4.89s\n",
            "  # 898\n",
            "    src: Video này đã có gần 50 triệu lượt xem vào năm nay .\n",
            "    ref: It &apos;s been viewed nearly 50 million times this year .\n",
            "    nmt: So this video has been around 50 million views this year .\n",
            "2019-01-21 16:05:28.895571: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:05:28.895580: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:05:28.895842: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model_2/best_bleu/translate.ckpt-13000, time 0.58s\n",
            "  eval dev: perplexity 13.33, time 5s, Mon Jan 21 16:05:34 2019.\n",
            "  eval test: perplexity 11.30, time 4s, Mon Jan 21 16:05:39 2019.\n",
            "2019-01-21 16:05:39.721470: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 16:05:39.721664: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 16:05:39.721797: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model_2/best_bleu/translate.ckpt-13000, time 0.61s\n",
            "# External evaluation, global step 13000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model_2/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 70s, Mon Jan 21 16:06:50 2019.\n",
            "  bleu dev: 20.3\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# External evaluation, global step 13000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model_2/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 63s, Mon Jan 21 16:07:54 2019.\n",
            "  bleu test: 22.5\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model_2/hparams\n",
            "# Best bleu, step 13000 lr 0.125 step-time 1.05s wps 5.29K ppl 1.97 gN 7.88 dev ppl 13.33, dev bleu 20.3, test ppl 11.30, test bleu 22.5, Mon Jan 21 16:07:55 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WHRv4ND_FBDV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ]
    },
    {
      "metadata": {
        "id": "1qXtrLI03mJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;\" > infer.vi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbPjbWWk3jqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2315
        },
        "outputId": "6a499084-5ea5-492e-ca8b-041ae26b77a6"
      },
      "cell_type": "code",
      "source": [
        "!python -m nmt.nmt \\\n",
        "    --out_dir=gdrive/My\\ Drive/nmt_attention_model_2 \\\n",
        "    --inference_list=0 \\\n",
        "    --inference_input_file=infer.vi \\\n",
        "    --inference_output_file=gdrive/My\\ Drive/output/infer.out"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Job id 0\n",
            "2019-01-21 05:28:11.424099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-21 05:28:11.424638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-21 05:28:11.424687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 05:28:11.798792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 05:28:11.798877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 05:28:11.798898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 05:28:11.799205: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-21 05:28:11.799312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 14597034667954536707), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11551642682026604675), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 10316763318708279934), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11281553818, 6803561884520604710)]\n",
            "# Loading hparams from gdrive/My Drive/nmt_attention_model/hparams\n",
            "# Vocab file nmt_data/vocab.vi exists\n",
            "# Vocab file nmt_data/vocab.en exists\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/best_bleu/hparams\n",
            "  attention=scaled_luong\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=0\n",
            "  best_bleu=21.659666588493305\n",
            "  best_bleu_dir=gdrive/My Drive/nmt_attention_model/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  decay_scheme=luong234\n",
            "  dev_prefix=nmt_data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=bi\n",
            "  eos=</s>\n",
            "  epoch_step=527\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=greedy\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=1.0\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=12000\n",
            "  num_translations_per_input=1\n",
            "  num_units=512\n",
            "  optimizer=sgd\n",
            "  out_dir=gdrive/My Drive/nmt_attention_model\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=nmt_data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=nmt_data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=nmt_data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=nmt_data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=nmt_data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
            "2019-01-21 05:28:13.139863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 05:28:13.139979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 05:28:13.140011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 05:28:13.140029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 05:28:13.140327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.44s\n",
            "# Start decoding\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/infer.out , num sents 1.\n",
            "  save attention image to gdrive/My Drive/nmt_attention_model/infer.out0.png*\n",
            "When I was a kid , I think <unk> was the best country in the world and I would like to sing , &quot; We don &apos;t have to envy . &quot;\n",
            "\n",
            "  done, time 0s, Mon Jan 21 05:28:14 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}