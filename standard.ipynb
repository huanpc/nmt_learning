{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F33sncleXVX6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Download Data"
      ]
    },
    {
      "metadata": {
        "id": "qx_-7-TJPINZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "929f525e-e823-46ed-9a94-ff51dc172bda"
      },
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jan  8 17:15 sample_data\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Akb1D6_sQhNY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNt9jBO7XU35",
        "colab_type": "code",
        "outputId": "6a01342b-f729-414f-b6d9-2734c261e5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -X GET https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/scripts/download_iwslt15.sh -o download_iwslt15.sh\n",
        "!chmod +x download_iwslt15.sh && ./download_iwslt15.sh nmt_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1188  100  1188    0     0   7200      0 --:--:-- --:--:-- --:--:--  7200\n",
            "mkdir: created directory 'nmt_data'\n",
            "Download training dataset train.en and train.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.9M  100 12.9M    0     0   720k      0  0:00:18  0:00:18 --:--:--  735k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17.2M  100 17.2M    0     0   691k      0  0:00:25  0:00:25 --:--:--  532k\n",
            "Download dev dataset tst2012.en and tst2012.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0   343k      0 --:--:-- --:--:-- --:--:--  343k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  183k  100  183k    0     0   323k      0 --:--:-- --:--:-- --:--:--  323k\n",
            "Download test dataset tst2013.en and tst2013.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  129k  100  129k    0     0   322k      0 --:--:-- --:--:-- --:--:--  322k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  179k  100  179k    0     0   378k      0 --:--:-- --:--:-- --:--:--  377k\n",
            "Download vocab file vocab.en and vocab.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0   316k      0 --:--:-- --:--:-- --:--:--  316k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 46767  100 46767    0     0   171k      0 --:--:-- --:--:-- --:--:--  171k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_kHz1Z0MPHFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e174b69-44ec-4291-8411-083c5ad87dfd"
      },
      "cell_type": "code",
      "source": [
        "# Upload the file to Drive. See:\n",
        "#\n",
        "# https://developers.google.com/drive/v3/reference/files/create\n",
        "# https://developers.google.com/drive/v3/web/manage-uploads\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'models.zip',\n",
        "  'mimeType': 'text/plain'\n",
        "}\n",
        "media = MediaFileUpload('download_iwslt15.sh', \n",
        "                        mimetype='application/octet-stream',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 15DUb94RPbIOsaEzwEwhJXk2X3-kFkr9P\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x0xVEaun4huM",
        "colab_type": "code",
        "outputId": "46154d0b-ef15-4610-8c45-93673fddba2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "-rwxr-xr-x 1 root root 1188 Jan 21 02:29 download_iwslt15.sh\n",
            "drwx------ 3 root root 4096 Jan 21 02:28 gdrive\n",
            "drwxr-xr-x 2 root root 4096 Jan 21 02:30 nmt_data\n",
            "drwxr-xr-x 1 root root 4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p7-VUfjd4mkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Clone code"
      ]
    },
    {
      "metadata": {
        "id": "ElTCEn4w4oMh",
        "colab_type": "code",
        "outputId": "fe15193b-8936-43e3-c019-755e412f95b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/nmt.git"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nmt'...\n",
            "remote: Enumerating objects: 1247, done.\u001b[K\n",
            "remote: Total 1247 (delta 0), reused 0 (delta 0), pack-reused 1247\u001b[K\n",
            "Receiving objects: 100% (1247/1247), 1.22 MiB | 8.85 MiB/s, done.\n",
            "Resolving deltas: 100% (892/892), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oEvdz_rS4r5L",
        "colab_type": "code",
        "outputId": "94e708ce-b80a-417d-9ed5-d7de2cbcbdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l nmt/nmt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 236\n",
            "-rw-r--r-- 1 root root  7387 Jan 21 02:37 attention_model.py\n",
            "drwxr-xr-x 3 root root  4096 Jan 21 02:37 g3doc\n",
            "-rw-r--r-- 1 root root 12252 Jan 21 02:37 gnmt_model.py\n",
            "-rw-r--r-- 1 root root  8895 Jan 21 02:37 inference.py\n",
            "-rw-r--r-- 1 root root  6490 Jan 21 02:37 inference_test.py\n",
            "-rw-r--r-- 1 root root     0 Jan 21 02:37 __init__.py\n",
            "-rw-r--r-- 1 root root 24395 Jan 21 02:37 model_helper.py\n",
            "-rw-r--r-- 1 root root 33588 Jan 21 02:37 model.py\n",
            "-rw-r--r-- 1 root root 48465 Jan 21 02:37 model_test.py\n",
            "-rw-r--r-- 1 root root 29123 Jan 21 02:37 nmt.py\n",
            "-rw-r--r-- 1 root root  3404 Jan 21 02:37 nmt_test.py\n",
            "drwxr-xr-x 2 root root  4096 Jan 21 02:37 scripts\n",
            "drwxr-xr-x 2 root root  4096 Jan 21 02:37 standard_hparams\n",
            "drwxr-xr-x 2 root root  4096 Jan 21 02:37 testdata\n",
            "-rw-r--r-- 1 root root 28948 Jan 21 02:37 train.py\n",
            "drwxr-xr-x 2 root root  4096 Jan 21 02:37 utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wx91RpEL5jeX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Tensor Board"
      ]
    },
    {
      "metadata": {
        "id": "G3j6Shf45wF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download"
      ]
    },
    {
      "metadata": {
        "id": "9DopEXs_5mCf",
        "colab_type": "code",
        "outputId": "9429caf1-d7d0-40c1-9caf-ac1fc1451f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!rm -rf ngrok\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-21 02:37:28--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.204.22.7, 34.206.9.96, 34.206.253.53, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.204.22.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  33%[=====>              ]   1.70M  7.88MB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  20.3MB/s    in 0.3s    \n",
            "\n",
            "2019-01-21 02:37:29 (20.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wK5U-QjPYbP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ]
    },
    {
      "metadata": {
        "id": "FA7zXiac5Fwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1 Basic"
      ]
    },
    {
      "metadata": {
        "id": "HKAdyn_x5tDk",
        "colab_type": "code",
        "outputId": "5030afd4-41c8-4443-b5a8-ca5105ff314b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1425
        }
      },
      "cell_type": "code",
      "source": [
        "tsboard_cmd = 'tensorboard --logdir nmt_model --host 0.0.0.0 --port 6006 &'\n",
        "print(\"Log dir\", tsboard_cmd)\n",
        "get_ipython().system_raw(tsboard_cmd)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log dir tensorboard --logdir nmt_model --host 0.0.0.0 --port 6006 &\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 106, in <module>\n",
            "    from .decoder import JSONDecoder, JSONDecodeError\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 53, in <module>\n",
            "    STRINGCHUNK = re.compile(r'(.*?)([\"\\\\\\x00-\\x1f])', FLAGS)\n",
            "  File \"/usr/lib/python3.6/re.py\", line 233, in compile\n",
            "    return _compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.6/re.py\", line 301, in _compile\n",
            "    p = sre_compile.compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 566, in compile\n",
            "    code = _code(p, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 551, in _code\n",
            "    _compile(code, p.data, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
            "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 72, in _compile\n",
            "    if (flags & SRE_FLAG_IGNORECASE and\n",
            "  File \"/usr/lib/python3.6/enum.py\", line 806, in __and__\n",
            "    return self.__class__(self._value_ & self.__class__(other)._value_)\n",
            "  File \"/usr/lib/python3.6/enum.py\", line 293, in __call__\n",
            "    return cls.__new__(cls, value)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-22e8f0c3fdd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsboard_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ngrok http 6006 &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)[\\'tunnels\\'][0][\\'public_url\\'])\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5ZuBbk8oXws4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf nmt_model \n",
        "!mkdir nmt_model\n",
        "!python -m nmt.nmt.nmt \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=nmt_data/vocab  \\\n",
        "    --train_prefix=nmt_data/train \\\n",
        "    --dev_prefix=nmt_data/tst2012  \\\n",
        "    --test_prefix=nmt_data/tst2013 \\\n",
        "    --out_dir=nmt_model \\\n",
        "    --num_train_steps=12000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --num_layers=4 \\\n",
        "    --num_units=128 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpK4sCR94Vxs",
        "colab_type": "code",
        "outputId": "ef4a5ed7-3517-4572-f8fa-34033746dd6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l nmt_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'nmt_model': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7RJzHsKS8f1t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Attention"
      ]
    },
    {
      "metadata": {
        "id": "BuHpV_t-Xcg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e01f9d9-795a-4494-f0af-a8bd2fbcf2e4"
      },
      "cell_type": "code",
      "source": [
        "# Clean old model\n",
        "!rm -rf gdrive/nmt_attention_model\n",
        "!mkdir gdrive/nmt_attention_model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘gdrive/nmt_attention_model’: Operation not supported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3eF1GR4z8h0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88a7f07b-5e36-4fee-9e28-98b32555aea9"
      },
      "cell_type": "code",
      "source": [
        "tsboard_cmd = 'tensorboard --logdir nmt_attention_model --host 0.0.0.0 --port 6006 &'\n",
        "print(\"Log dir\", tsboard_cmd)\n",
        "get_ipython().system_raw(tsboard_cmd)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log dir tensorboard --logdir nmt_attention_model --host 0.0.0.0 --port 6006 &\n",
            "http://0c7abc4e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kLkoA0vqjP-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4d88f560-4d4a-4d29-c5c8-2e6e59381a70"
      },
      "cell_type": "code",
      "source": [
        "!curl -X GET https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/standard_hparams/iwslt15.json -o params.json"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   823  100   823    0     0   7620      0 --:--:-- --:--:-- --:--:--  7550\r100   823  100   823    0     0   7550      0 --:--:-- --:--:-- --:--:--  7550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Th2bEXxb8dMQ",
        "colab_type": "code",
        "outputId": "a01f6121-fe15-4e83-f8d5-47665af39c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4695
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m nmt.nmt.nmt \\\n",
        "    --attention=scaled_luong \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=nmt_data/vocab  \\\n",
        "    --train_prefix=nmt_data/train \\\n",
        "    --dev_prefix=nmt_data/tst2012  \\\n",
        "    --test_prefix=nmt_data/tst2013 \\\n",
        "    --out_dir=gdrive/My\\ Drive/nmt_attention_model \\\n",
        "    --num_train_steps=12000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --infer_mode=beam_search\\\n",
        "    --beam_width=10\\\n",
        "    --num_layers=2 \\\n",
        "    --num_units=512 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu \\\n",
        "    --encoder_type=bi\\\n",
        "    --decay_scheme=luong234\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Job id 0\n",
            "2019-01-21 05:08:44.199210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-21 05:08:44.199958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-21 05:08:44.200029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 05:08:44.725430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 05:08:44.725520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 05:08:44.725543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 05:08:44.725853: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-21 05:08:44.725931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 5198774790963353161), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17884553635549527800), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 18425440272724687229), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11281553818, 2632582583236165807)]\n",
            "# Loading hparams from gdrive/My Drive/nmt_attention_model/hparams\n",
            "# Vocab file nmt_data/vocab.vi exists\n",
            "# Vocab file nmt_data/vocab.en exists\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/best_bleu/hparams\n",
            "  attention=scaled_luong\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=10\n",
            "  best_bleu=21.659666588493305\n",
            "  best_bleu_dir=gdrive/My Drive/nmt_attention_model/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  decay_scheme=luong234\n",
            "  dev_prefix=nmt_data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=bi\n",
            "  eos=</s>\n",
            "  epoch_step=527\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=beam_search\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=1.0\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=12000\n",
            "  num_translations_per_input=1\n",
            "  num_units=512\n",
            "  optimizer=sgd\n",
            "  out_dir=gdrive/My Drive/nmt_attention_model\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=nmt_data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=nmt_data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=nmt_data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=nmt_data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=nmt_data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "# Creating train graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  learning_rate=1, warmup_steps=0, warmup_scheme=t2t\n",
            "  decay_scheme=luong234, start_decay_step=8000, decay_steps 1000, decay_factor 0.5\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), /device:GPU:0\n",
            "# Creating eval graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), /device:GPU:0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=beam_searchbeam_width=10, length_penalty=0.000000\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
            "# log_file=gdrive/My Drive/nmt_attention_model/log_1548047331\n",
            "2019-01-21 05:08:51.394815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 05:08:51.394904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 05:08:51.394941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 05:08:51.394971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 05:08:51.395241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-01-21 05:08:51.395649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 05:08:51.395703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 05:08:51.395727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 05:08:51.395741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 05:08:51.395990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-01-21 05:08:51.396555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-21 05:08:51.396598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-21 05:08:51.396620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-21 05:08:51.396635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-21 05:08:51.396928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "  loaded train model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.52s\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.31s\n",
            "  # 910\n",
            "    src: Bạn có thể viết kịch bản gì chứa đựng điều này trong đó ?\n",
            "    ref: What scripts could you have written that would have contained this in it ?\n",
            "    nmt: Can you write something like this in that ?\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.39s\n",
            "  eval dev: perplexity 9.94, time 3s, Mon Jan 21 05:08:57 2019.\n",
            "  eval test: perplexity 8.76, time 2s, Mon Jan 21 05:09:00 2019.\n",
            "2019-01-21 05:09:00.869089: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:09:00.869318: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:09:00.869433: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.41s\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 41s, Mon Jan 21 05:09:42 2019.\n",
            "  bleu dev: 21.4\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 38s, Mon Jan 21 05:10:21 2019.\n",
            "  bleu test: 24.9\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "# Start step 12000, lr 0.0625, Mon Jan 21 05:10:21 2019\n",
            "# Init train iterator, skipping 67456 elements\n",
            "2019-01-21 05:10:22.852291: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:10:22.852544: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:10:22.852726: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.26s\n",
            "  # 1275\n",
            "    src: Khi người này giúp người kia , cộng đồng của chúng ta trở nên lớn mạnh hơn .\n",
            "    ref: When one neighbor helps another , we strengthen our communities .\n",
            "    nmt: When this person is helping the other , our communities get bigger .\n",
            "2019-01-21 05:10:23.229376: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:10:23.229633: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:10:23.229772: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.25s\n",
            "  eval dev: perplexity 9.94, time 3s, Mon Jan 21 05:10:26 2019.\n",
            "  eval test: perplexity 8.76, time 2s, Mon Jan 21 05:10:29 2019.\n",
            "2019-01-21 05:10:29.829887: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:10:29.830153: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:10:29.830291: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/translate.ckpt-12000, time 0.27s\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 42s, Mon Jan 21 05:11:12 2019.\n",
            "  bleu dev: 21.4\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 38s, Mon Jan 21 05:11:51 2019.\n",
            "  bleu test: 24.9\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "# Final, step 12000 lr 0.0625 step-time 0.00s wps 0.00K ppl 0.00 gN 0.00 dev ppl 9.94, dev bleu 21.4, test ppl 8.76, test bleu 24.9, Mon Jan 21 05:11:52 2019\n",
            "# Done training!, time 90s, Mon Jan 21 05:11:52 2019.\n",
            "# Start evaluating saved best models.\n",
            "2019-01-21 05:11:52.656561: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:11:52.656810: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:11:52.656833: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/best_bleu/translate.ckpt-11000, time 0.30s\n",
            "  # 121\n",
            "    src: Và một trong những điều nổi bật nhất mà tôi nhận ra được trong khoảng thời gian ngắn tôi đến đây đó là TED có một bản sắn riêng của mình .\n",
            "    ref: And one of the things that &apos;s emerged in my short time here is that TED has an identity .\n",
            "    nmt: And one of the most striking things I &apos;ve found over my short time is that TED has a personal <unk> .\n",
            "2019-01-21 05:11:53.137719: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:11:53.137919: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:11:53.138045: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/nmt_attention_model/best_bleu/translate.ckpt-11000, time 0.28s\n",
            "  eval dev: perplexity 9.88, time 3s, Mon Jan 21 05:11:56 2019.\n",
            "  eval test: perplexity 8.68, time 2s, Mon Jan 21 05:11:59 2019.\n",
            "2019-01-21 05:11:59.549281: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-21 05:11:59.549561: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-21 05:11:59.549687: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/nmt_attention_model/best_bleu/translate.ckpt-11000, time 0.28s\n",
            "# External evaluation, global step 11000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 41s, Mon Jan 21 05:12:41 2019.\n",
            "  bleu dev: 21.7\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "# External evaluation, global step 11000\n",
            "  decoding to output gdrive/My Drive/nmt_attention_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 40s, Mon Jan 21 05:13:22 2019.\n",
            "  bleu test: 24.4\n",
            "  saving hparams to gdrive/My Drive/nmt_attention_model/hparams\n",
            "# Best bleu, step 11000 lr 0.0625 step-time 0.00s wps 0.00K ppl 0.00 gN 0.00 dev ppl 9.88, dev bleu 21.7, test ppl 8.68, test bleu 24.4, Mon Jan 21 05:13:22 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UoiJ1T5us6sB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "beaba983-493f-4d30-ecc0-80074f4d0646"
      },
      "cell_type": "code",
      "source": [
        "!rm -f models.zip\n",
        "!zip -r9 models.zip nmt_attention_model\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: nmt_attention_model/ (stored 0%)\n",
            "  adding: nmt_attention_model/translate.ckpt-8000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/translate.ckpt-12000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/translate.ckpt-8000.data-00000-of-00001 (deflated 8%)\n",
            "  adding: nmt_attention_model/translate.ckpt-9000.meta (deflated 93%)\n",
            "  adding: nmt_attention_model/translate.ckpt-10000.data-00000-of-00001 (deflated 7%)\n",
            "  adding: nmt_attention_model/checkpoint (deflated 75%)\n",
            "  adding: nmt_attention_model/translate.ckpt-11000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/translate.ckpt-12000.data-00000-of-00001 (deflated 7%)\n",
            "  adding: nmt_attention_model/output_dev (deflated 67%)\n",
            "  adding: nmt_attention_model/best_bleu/ (stored 0%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-7000.meta (deflated 92%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-7000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-6000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-7000.data-00000-of-00001 (deflated 8%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-5000.data-00000-of-00001 (deflated 8%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-10000.data-00000-of-00001 (deflated 7%)\n",
            "  adding: nmt_attention_model/best_bleu/checkpoint (deflated 75%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-11000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-6000.meta (deflated 92%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-10000.meta (deflated 92%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-11000.data-00000-of-00001 (deflated 7%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-6000.data-00000-of-00001 (deflated 8%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-11000.meta (deflated 92%)\n",
            "  adding: nmt_attention_model/best_bleu/hparams (deflated 64%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-5000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-5000.meta (deflated 92%)\n",
            "  adding: nmt_attention_model/best_bleu/train_log/ (stored 0%)\n",
            "  adding: nmt_attention_model/best_bleu/train_log/events.out.tfevents.1548008448.25874bfa7f76 (deflated 92%)\n",
            "  adding: nmt_attention_model/best_bleu/translate.ckpt-10000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/translate.ckpt-9000.index (deflated 44%)\n",
            "  adding: nmt_attention_model/translate.ckpt-10000.meta (deflated 93%)\n",
            "  adding: nmt_attention_model/output_test (deflated 66%)\n",
            "  adding: nmt_attention_model/translate.ckpt-11000.data-00000-of-00001 (deflated 7%)\n",
            "  adding: nmt_attention_model/translate.ckpt-9000.data-00000-of-00001 (deflated 8%)\n",
            "  adding: nmt_attention_model/translate.ckpt-12000.meta (deflated 93%)\n",
            "  adding: nmt_attention_model/translate.ckpt-11000.meta (deflated 93%)\n",
            "  adding: nmt_attention_model/hparams (deflated 64%)\n",
            "  adding: nmt_attention_model/translate.ckpt-8000.meta (deflated 94%)\n",
            "  adding: nmt_attention_model/log_1548001254 (deflated 83%)\n",
            "  adding: nmt_attention_model/train_log/ (stored 0%)\n",
            "  adding: nmt_attention_model/train_log/events.out.tfevents.1548001255.25874bfa7f76 (deflated 88%)\n",
            "  adding: nmt_attention_model/translate.ckpt-10000.index (deflated 44%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}