{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F33sncleXVX6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Download Data"
      ]
    },
    {
      "metadata": {
        "id": "qx_-7-TJPINZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "49871e21-bfe3-4845-c6bb-ebe6c4bffc1a"
      },
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jan  8 17:15 sample_data\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zPT869TFPyR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/My\\ Drive/nmt/nmt_data nmt_data\n",
        "!cp -r 'gdrive/My Drive/nmt/nmt' nmt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GhN2dyx39zlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2523c5d8-6d35-494b-fdaf-73c361bf4512"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 21004\n",
            "drwx------ 3 root root     4096 Jan 22 02:26 gdrive\n",
            "drwxr-xr-x 2 root root     4096 Jan 22 02:27 model_temp\n",
            "-rwxr-xr-x 1 root root 16117632 Jul 15  2017 ngrok\n",
            "-rw-r--r-- 1 root root  5363700 Jan 22 02:27 ngrok-stable-linux-amd64.zip\n",
            "drwx------ 8 root root     4096 Jan 22 02:34 nmt\n",
            "drwx------ 3 root root     4096 Jan 22 02:33 nmt_data\n",
            "drwxr-xr-x 1 root root     4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNt9jBO7XU35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir gdrive/My\\ Drive/nmt\n",
        "# !curl -X GET https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/scripts/download_iwslt15.sh -o gdrive/My\\ Drive/nmt/download_iwslt15.sh\n",
        "# !mkdir gdrive/My\\ Drive/nmt/nmt_data\n",
        "# !chmod +x gdrive/My\\ Drive/nmt/download_iwslt15.sh && ./gdrive/My\\ Drive/nmt/download_iwslt15.sh gdrive/My\\ Drive/nmt/nmt_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7-VUfjd4mkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Clone code"
      ]
    },
    {
      "metadata": {
        "id": "ElTCEn4w4oMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !cd gdrive/My\\ Drive/nmt && git clone https://github.com/tensorflow/nmt.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rn9r90w-tAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!CODE_DIR=\"gdrive/My\\ Drive/nmt\"\n",
        "!DATA_DIR=\"gdrive/My\\ Drive/nmt/nmt_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wx91RpEL5jeX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Tensor Board"
      ]
    },
    {
      "metadata": {
        "id": "G3j6Shf45wF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download"
      ]
    },
    {
      "metadata": {
        "id": "9DopEXs_5mCf",
        "colab_type": "code",
        "outputId": "65f3b1d3-79ab-46c7-b8b7-39ce4c514ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!rm -rf ngrok\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-22 02:27:00--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.165.51.142, 52.7.169.168, 52.45.248.161, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.165.51.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  3.46MB/s    in 1.5s    \n",
            "\n",
            "2019-01-22 02:27:03 (3.46 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wK5U-QjPYbP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ]
    },
    {
      "metadata": {
        "id": "FA7zXiac5Fwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1 Basic"
      ]
    },
    {
      "metadata": {
        "id": "HKAdyn_x5tDk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tsboard_cmd = 'tensorboard --logdir nmt_model --host 0.0.0.0 --port 6006 &'\n",
        "# print(\"Log dir\", tsboard_cmd)\n",
        "# get_ipython().system_raw(tsboard_cmd)\n",
        "# get_ipython().system_raw('./ngrok http 6006 &')\n",
        "# !curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZuBbk8oXws4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !rm -rf nmt_model \n",
        "# !mkdir nmt_model\n",
        "# !python -m nmt.nmt.nmt \\\n",
        "#     --src=vi --tgt=en \\\n",
        "#     --vocab_prefix=nmt_data/vocab  \\\n",
        "#     --train_prefix=nmt_data/train \\\n",
        "#     --dev_prefix=nmt_data/tst2012  \\\n",
        "#     --test_prefix=nmt_data/tst2013 \\\n",
        "#     --out_dir=nmt_model \\\n",
        "#     --num_train_steps=12000 \\\n",
        "#     --steps_per_stats=100 \\\n",
        "#     --num_layers=4 \\\n",
        "#     --num_units=128 \\\n",
        "#     --dropout=0.2 \\\n",
        "#     --metrics=bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RJzHsKS8f1t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Attention"
      ]
    },
    {
      "metadata": {
        "id": "3eF1GR4z8h0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8d3d367-2df7-49f1-fc24-0f3146326777"
      },
      "cell_type": "code",
      "source": [
        "tsboard_cmd = 'tensorboard --logdir nmt_attention_model_2 --host 0.0.0.0 --port 6006 &'\n",
        "print(\"Log dir\", tsboard_cmd)\n",
        "get_ipython().system_raw(tsboard_cmd)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log dir tensorboard --logdir nmt_attention_model_2 --host 0.0.0.0 --port 6006 &\n",
            "https://5695038a.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Th2bEXxb8dMQ",
        "colab_type": "code",
        "outputId": "f34c53ff-74c7-44fe-9d4a-37b92cc06767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4695
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m nmt.nmt \\\n",
        "    --attention=scaled_luong \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=nmt_data/vocab  \\\n",
        "    --train_prefix=nmt_data/train \\\n",
        "    --dev_prefix=nmt_data/tst2012  \\\n",
        "    --test_prefix=nmt_data/tst2013 \\\n",
        "    --out_dir=gdrive/My\\ Drive/model_temp \\\n",
        "    --num_train_steps=12000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --optimizer=adam \\\n",
        "    --learning_rate=0.001 \\\n",
        "    --infer_mode=beam_search\\\n",
        "    --beam_width=10\\\n",
        "    --num_layers=2 \\\n",
        "    --num_units=512 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu \\\n",
        "    --encoder_type=bi\\\n",
        "    --decay_scheme=luong234\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Job id 0\n",
            "2019-01-22 02:51:49.471311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-22 02:51:49.471761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-22 02:51:49.471798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-22 02:51:50.414926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-22 02:51:50.415111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-22 02:51:50.415138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-22 02:51:50.415445: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-22 02:51:50.415542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 9288426584350008676), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13747519634574730038), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 20615043470257164), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11281553818, 8849619025042437123)]\n",
            "# Loading hparams from gdrive/My Drive/model_temp/hparams\n",
            "# Vocab file nmt_data/vocab.vi exists\n",
            "# Vocab file nmt_data/vocab.en exists\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "  saving hparams to gdrive/My Drive/model_temp/best_bleu/hparams\n",
            "  attention=scaled_luong\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=10\n",
            "  best_bleu=20.411993801388295\n",
            "  best_bleu_dir=gdrive/My Drive/model_temp/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  decay_scheme=luong234\n",
            "  dev_prefix=nmt_data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=bi\n",
            "  eos=</s>\n",
            "  epoch_step=527\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=beam_search\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=0.001\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=12000\n",
            "  num_translations_per_input=1\n",
            "  num_units=512\n",
            "  optimizer=adam\n",
            "  out_dir=gdrive/My Drive/model_temp\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=nmt_data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=nmt_data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=nmt_data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=nmt_data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=nmt_data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "WARNING:tensorflow:From /content/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "# Creating train graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  learning_rate=0.001, warmup_steps=0, warmup_scheme=t2t\n",
            "  decay_scheme=luong234, start_decay_step=8000, decay_steps 1000, decay_factor 0.5\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), /device:GPU:0\n",
            "# Creating eval graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), /device:GPU:0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=beam_searchbeam_width=10, length_penalty=0.000000\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
            "# log_file=gdrive/My Drive/model_temp/log_1548125518\n",
            "2019-01-22 02:51:58.666872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-22 02:51:58.666947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-22 02:51:58.666967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-22 02:51:58.666988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-22 02:51:58.667265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-01-22 02:51:58.667637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-22 02:51:58.667675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-22 02:51:58.667713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-22 02:51:58.667729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-22 02:51:58.668034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-01-22 02:51:58.668554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-22 02:51:58.668598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-22 02:51:58.668620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-22 02:51:58.668635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-22 02:51:58.668905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "  loaded train model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 11.37s\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.32s\n",
            "  # 230\n",
            "    src: ý tôi là , thật khó tin !\n",
            "    ref: I mean , it &apos;s fascinating .\n",
            "    nmt: I mean , it &apos;s incredible .\n",
            "  loaded eval model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.28s\n",
            "  eval dev: perplexity 15.08, time 3s, Tue Jan 22 02:52:15 2019.\n",
            "  eval test: perplexity 12.82, time 2s, Tue Jan 22 02:52:18 2019.\n",
            "2019-01-22 02:52:18.835877: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:52:18.836032: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:52:18.836143: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.25s\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/model_temp/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 37s, Tue Jan 22 02:52:56 2019.\n",
            "  bleu dev: 19.9\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/model_temp/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 36s, Tue Jan 22 02:53:33 2019.\n",
            "  bleu test: 22.8\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "# Start step 12000, lr 6.25e-05, Tue Jan 22 02:53:34 2019\n",
            "# Init train iterator, skipping 67456 elements\n",
            "2019-01-22 02:53:36.239284: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:53:36.239485: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:53:36.239611: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.27s\n",
            "  # 350\n",
            "    src: Sáng hôm sau , tôi thức dậy và nghĩ , tôi đã mơ về một bản kiến nghị điên rồ hay tôi thực sự đã viết nó ?\n",
            "    ref: And the next morning , I woke up and I thought , now did I dream that crazy motion , or did I actually write it ?\n",
            "    nmt: The next morning , I woke up and thought , well , I thought about a crazy intervention or I wrote it ?\n",
            "2019-01-22 02:53:36.721917: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:53:36.721935: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:53:36.722441: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.26s\n",
            "  eval dev: perplexity 15.08, time 2s, Tue Jan 22 02:53:39 2019.\n",
            "  eval test: perplexity 12.82, time 2s, Tue Jan 22 02:53:42 2019.\n",
            "2019-01-22 02:53:42.545064: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:53:42.545079: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:53:42.545277: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.26s\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/model_temp/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 37s, Tue Jan 22 02:54:20 2019.\n",
            "  bleu dev: 19.9\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output gdrive/My Drive/model_temp/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 36s, Tue Jan 22 02:54:56 2019.\n",
            "  bleu test: 22.8\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "# Final, step 12000 lr 6.25e-05 step-time 0.00s wps 0.00K ppl 0.00 gN 0.00 dev ppl 15.08, dev bleu 19.9, test ppl 12.82, test bleu 22.8, Tue Jan 22 02:54:57 2019\n",
            "# Done training!, time 83s, Tue Jan 22 02:54:57 2019.\n",
            "# Start evaluating saved best models.\n",
            "2019-01-22 02:55:03.061153: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:55:03.061356: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:55:03.061470: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/best_bleu/translate.ckpt-4000, time 5.25s\n",
            "  # 1289\n",
            "    src: Đó chính là những gì OccupytheSEC đã làm .\n",
            "    ref: So that &apos;s OccupytheSEC movement has done .\n",
            "    nmt: That &apos;s what <unk> did .\n",
            "2019-01-22 02:55:03.382505: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:55:03.382667: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:55:03.382773: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from gdrive/My Drive/model_temp/best_bleu/translate.ckpt-4000, time 0.25s\n",
            "  eval dev: perplexity 10.66, time 2s, Tue Jan 22 02:55:06 2019.\n",
            "  eval test: perplexity 9.55, time 2s, Tue Jan 22 02:55:08 2019.\n",
            "2019-01-22 02:55:09.220899: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.vi is already initialized.\n",
            "2019-01-22 02:55:09.221111: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "2019-01-22 02:55:09.221206: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/best_bleu/translate.ckpt-4000, time 0.26s\n",
            "# External evaluation, global step 4000\n",
            "  decoding to output gdrive/My Drive/model_temp/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 43s, Tue Jan 22 02:55:52 2019.\n",
            "  bleu dev: 20.4\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "# External evaluation, global step 4000\n",
            "  decoding to output gdrive/My Drive/model_temp/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 42s, Tue Jan 22 02:56:35 2019.\n",
            "  bleu test: 22.9\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "# Best bleu, step 4000 lr 6.25e-05 step-time 0.00s wps 0.00K ppl 0.00 gN 0.00 dev ppl 10.66, dev bleu 20.4, test ppl 9.55, test bleu 22.9, Tue Jan 22 02:56:35 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WHRv4ND_FBDV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ]
    },
    {
      "metadata": {
        "id": "1qXtrLI03mJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;\" > infer.vi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbPjbWWk3jqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2349
        },
        "outputId": "a149d09f-db9f-4454-e6e9-3005ab0a6ffc"
      },
      "cell_type": "code",
      "source": [
        "!python -m nmt.nmt \\\n",
        "    --out_dir=gdrive/My\\ Drive/model_temp \\\n",
        "    --inference_list=0 \\\n",
        "    --vocab_prefix=nmt_data/vocab  \\\n",
        "    --inference_input_file=infer.vi \\\n",
        "    --inference_output_file=gdrive/My\\ Drive/output/infer.out"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Job id 0\n",
            "2019-01-22 04:33:04.172176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-22 04:33:04.172682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-22 04:33:04.172715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-22 04:33:04.520536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-22 04:33:04.520601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-22 04:33:04.520647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-22 04:33:04.520894: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-22 04:33:04.520960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 7915891060114048164), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14668767086022046359), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 14831002496812043730), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11281553818, 6869160250073548286)]\n",
            "# Loading hparams from gdrive/My Drive/model_temp/hparams\n",
            "# Updating hparams.beam_width: 10 -> 0\n",
            "# Updating hparams.infer_mode: beam_search -> greedy\n",
            "# Vocab file nmt_data/vocab.vi exists\n",
            "# Vocab file nmt_data/vocab.en exists\n",
            "  saving hparams to gdrive/My Drive/model_temp/hparams\n",
            "  saving hparams to gdrive/My Drive/model_temp/best_bleu/hparams\n",
            "  attention=scaled_luong\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=0\n",
            "  best_bleu=20.411993801388295\n",
            "  best_bleu_dir=gdrive/My Drive/model_temp/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  decay_scheme=luong234\n",
            "  dev_prefix=nmt_data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=bi\n",
            "  eos=</s>\n",
            "  epoch_step=527\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=greedy\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=0.001\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=12000\n",
            "  num_translations_per_input=1\n",
            "  num_units=512\n",
            "  optimizer=adam\n",
            "  out_dir=gdrive/My Drive/model_temp\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=nmt_data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=nmt_data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=nmt_data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=nmt_data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=nmt_data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_bi_layers = 1, num_bi_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (1024, 512), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (1536, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
            "2019-01-22 04:33:05.611121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-22 04:33:05.611189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-22 04:33:05.611270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-22 04:33:05.611286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-22 04:33:05.611559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "  loaded infer model parameters from gdrive/My Drive/model_temp/translate.ckpt-12000, time 0.43s\n",
            "# Start decoding\n",
            "  decoding to output gdrive/My Drive/output/infer.out , num sents 1.\n",
            "  save attention image to gdrive/My Drive/output/infer.out0.png*\n",
            "When I was a kid , I thought that <unk> was the best country in the world , and I would often like to sing &quot; We should be <unk> . &quot;\n",
            "\n",
            "  done, time 0s, Tue Jan 22 04:33:06 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}